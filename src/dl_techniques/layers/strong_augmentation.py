"""Apply strong data augmentations for consistency-based regularization.

This layer implements a sequence of aggressive data augmentations, specifically
color jittering and CutMix, which are fundamental to consistency regularization
techniques in modern semi-supervised and self-supervised learning. The primary
goal is to generate a heavily distorted or "strong" view of an input image,
forcing the model to learn representations that are invariant to significant
photometric and geometric changes.

In a typical consistency-based training framework (e.g., FixMatch), a model is
trained to produce the same output distribution for a weakly-augmented version
of an image and a strongly-augmented version produced by this layer. This
enforces representational invariance and is a powerful regularizer.

Architectural and Mathematical Underpinnings:

The layer applies two distinct classes of augmentation sequentially:

1.  **Photometric Distortion (Color Jittering)**: This step alters the pixel
    value distribution of the image without changing its geometric content. It
    randomly modifies the brightness and contrast, forcing the model to become
    robust to variations in lighting and camera properties.
    -   **Brightness**: `I_new = I * α`, where `α` is a random factor.
    -   **Contrast**: `I_new = (I - μ) * β + μ`, where `μ` is the mean pixel
        value and `β` is a random factor.

2.  **Geometric and Contextual Mixing (CutMix)**: This technique serves as a
    powerful regularizer by combining two images. It acts as a form of
    regional dropout that encourages the model to learn from partial views
    and improves its ability to localize objects.
    -   **Process**: Given two images `x_a` and `x_b` from a batch, a random
        rectangular patch is sampled from `x_b` and pasted over the
        corresponding region in `x_a`.
    -   **Formulation**: The new image `x_new` is generated by:
        `x_new = M ⊙ x_b + (1 - M) ⊙ x_a`
        where `M` is a binary mask with a rectangular region of ones, and `⊙`
        denotes element-wise multiplication. By forcing the model to make
        predictions based on this composite image, it learns to utilize features
        from the entire image rather than focusing on a small subset of
        discriminative features.

This combination of strong photometric and geometric augmentations is crucial for
preventing overfitting and learning robust, generalizable visual
representations from limited labeled data.

References:
    - Yun, S., et al. (2019). CutMix: Regularization Strategy to Train Strong
      Classifiers with Localizable Features. *ICCV*.
    - Sohn, K., et al. (2020). FixMatch: Simplifying Semi-Supervised Learning
      with Consistency and Confidence. *NeurIPS*.
    - Krizhevsky, A., et al. (2012). ImageNet Classification with Deep
      Convolutional Neural Networks. *NeurIPS*. (Early use of color
      augmentation).
"""

import keras
from keras import ops
from typing import Dict, Tuple, Any

# ---------------------------------------------------------------------

@keras.saving.register_keras_serializable()
class StrongAugmentation(keras.layers.Layer):
    """Strong augmentation layer for unlabeled data.

    Implements color jittering and CutMix augmentations using Keras operations
    for backend compatibility.

    Args:
        cutmix_prob: Float, probability of applying CutMix augmentation.
        cutmix_ratio_range: Tuple of floats, range for CutMix cut ratio.
        color_jitter_strength: Float, strength of color jittering.
        **kwargs: Additional keyword arguments for the Layer base class.
    """

    def __init__(
            self,
            cutmix_prob: float = 0.5,
            cutmix_ratio_range: Tuple[float, float] = (0.1, 0.5),
            color_jitter_strength: float = 0.2,
            **kwargs: Any
    ) -> None:
        super().__init__(**kwargs)
        self.cutmix_prob = cutmix_prob
        self.cutmix_ratio_range = cutmix_ratio_range
        self.color_jitter_strength = color_jitter_strength

    def call(self, inputs: keras.KerasTensor, training: bool = None) -> keras.KerasTensor:
        """Apply strong augmentations to input images.

        Args:
            inputs: Input images tensor with shape (batch_size, height, width, channels).
            training: Boolean indicating whether in training mode.

        Returns:
            Augmented images tensor with same shape as input.
        """
        if not training:
            return inputs

        # Apply color jittering
        x = self._apply_color_jitter(inputs)

        # Apply CutMix with probability
        x = self._apply_cutmix(x)

        return x

    def _apply_color_jitter(self, x: keras.KerasTensor) -> keras.KerasTensor:
        """Apply color jittering augmentation.

        Args:
            x: Input images tensor.

        Returns:
            Color-jittered images tensor.
        """
        # Brightness adjustment
        brightness_factor = ops.random.uniform(
            shape=(),
            minval=1.0 - self.color_jitter_strength,
            maxval=1.0 + self.color_jitter_strength
        )
        x = ops.multiply(x, brightness_factor)

        # Contrast adjustment
        contrast_factor = ops.random.uniform(
            shape=(),
            minval=1.0 - self.color_jitter_strength,
            maxval=1.0 + self.color_jitter_strength
        )
        mean_val = ops.mean(x, axis=[1, 2, 3], keepdims=True)
        x = ops.multiply(ops.subtract(x, mean_val), contrast_factor) + mean_val

        # Clip to valid range
        x = ops.clip(x, 0.0, 1.0)

        return x

    def _apply_cutmix(self, x: keras.KerasTensor) -> keras.KerasTensor:
        """Apply CutMix augmentation.

        Args:
            x: Input images tensor.

        Returns:
            CutMix-augmented images tensor.
        """
        # Apply CutMix with probability
        should_apply = ops.random.uniform(shape=()) < self.cutmix_prob

        if not should_apply:
            return x

        batch_size = ops.shape(x)[0]
        height, width = ops.shape(x)[1], ops.shape(x)[2]

        # Generate random permutation
        perm_indices = ops.random.shuffle(ops.arange(batch_size))
        x_perm = ops.take(x, perm_indices, axis=0)

        # Generate random cut ratio
        cut_ratio = ops.random.uniform(
            shape=(),
            minval=self.cutmix_ratio_range[0],
            maxval=self.cutmix_ratio_range[1]
        )

        # Calculate cut dimensions
        cut_h = ops.cast(ops.cast(height, "float32") * cut_ratio, "int32")
        cut_w = ops.cast(ops.cast(width, "float32") * cut_ratio, "int32")

        # Generate random cut position
        cut_y = ops.random.uniform(
            shape=(),
            minval=0,
            maxval=height - cut_h,
            dtype="int32"
        )
        cut_x = ops.random.uniform(
            shape=(),
            minval=0,
            maxval=width - cut_w,
            dtype="int32"
        )

        # Create mask
        mask = ops.zeros((height, width, 1))
        ones_patch = ops.ones((cut_h, cut_w, 1))

        # Apply patch to mask (simplified approach)
        # In practice, you might want to use more sophisticated masking
        mask = ops.where(
            ops.logical_and(
                ops.logical_and(
                    ops.arange(height)[:, None] >= cut_y,
                    ops.arange(height)[:, None] < cut_y + cut_h
                ),
                ops.logical_and(
                    ops.arange(width)[None, :] >= cut_x,
                    ops.arange(width)[None, :] < cut_x + cut_w
                )
            )[:, :, None],
            ops.ones_like(mask),
            mask
        )

        # Apply mask to all channels
        mask = ops.tile(mask, [1, 1, 3])

        # Mix images
        x = ops.multiply(x, ops.subtract(1.0, mask)) + ops.multiply(x_perm, mask)

        return x

    def get_config(self) -> Dict[str, Any]:
        """Get layer configuration."""
        config = super().get_config()
        config.update({
            "cutmix_prob": self.cutmix_prob,
            "cutmix_ratio_range": self.cutmix_ratio_range,
            "color_jitter_strength": self.color_jitter_strength,
        })
        return config

# ---------------------------------------------------------------------
