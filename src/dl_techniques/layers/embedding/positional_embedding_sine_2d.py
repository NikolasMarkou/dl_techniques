"""
Generate 2D sinusoidal positional encodings for image-like inputs.

This layer implements the 2D sinusoidal positional encoding scheme, a critical
component for injecting spatial awareness into attention-based models like
Vision Transformers. Self-attention mechanisms are permutation-equivariant and
lack any inherent understanding of the spatial arrangement of input tokens (e.g.,
image patches or feature map pixels). This layer provides a fixed, non-learnable
encoding that gives the model a unique signal for each absolute position in the
2D grid.

Architecture and Foundational Mathematics:
The method is a direct two-dimensional extension of the 1D positional
encodings introduced in the original Transformer model. The core idea is to
use sine and cosine functions of varying frequencies to create a unique vector
for each position.

For a 2D feature map of shape `(H, W)`, the encoding is generated by
independently creating positional vectors for the y-axis (height) and the
x-axis (width) and then concatenating them.

For any given position `pos` along a single axis (either x or y) and a
given channel index `i` in the embedding space, the encoding is calculated
as:

    PE(pos, 2i)   = sin(pos / T^(2i / d))
    PE(pos, 2i+1) = cos(pos / T^(2i / d))

Where:
- `pos` is the integer coordinate (e.g., 0, 1, 2, ...).
- `d` is the dimensionality of the positional encoding for a single axis
  (`num_pos_feats`).
- `i` is the dimension index, `0 <= i < d/2`.
- `T` is a large constant `temperature` (e.g., 10000).

The wavelengths of the sinusoids form a geometric progression, from `2π` to
`2π * T`. This allows the model to represent positions as a combination of
signals at different frequencies. A key intuition is that this formulation
enables the model to easily learn relative positions. Due to trigonometric
identities, for any fixed offset `k`, `PE(pos + k)` can be represented as a
linear transformation of `PE(pos)`, making it simple for the attention
mechanism to learn how to attend to relative spatial locations.

The final output for a spatial location `(y, x)` is the channel-wise
concatenation of the y-encoding and the x-encoding, resulting in a feature
dimension of `2 * d`.

References:
  - "Attention Is All You Need" (Vaswani et al., 2017)
    https://arxiv.org/abs/1706.03762
  - "End-to-End Object Detection with Transformers" (Carion et al., 2020)
    https://arxiv.org/abs/2005.12872

"""

import math
import keras
from keras import ops
from typing import Optional, Dict, Any, Tuple

# ---------------------------------------------------------------------

@keras.saving.register_keras_serializable()
class PositionEmbeddingSine2D(keras.layers.Layer):
    """
    Generates 2D sinusoidal positional encodings for image-like feature maps.

    This layer creates fixed, non-learnable 2D positional encodings based on sine
    and cosine functions of different frequencies. These encodings provide spatial
    awareness to models like transformers when processing 2D data. The generated
    encodings are typically added to the input feature map.

    **Intent**: Provide a standard, non-learnable method for encoding spatial
    information in 2D feature maps, critical for attention-based models that
    do not inherently process positional data.

    **Architecture**:
    ```
    Input(shape=[batch, H, W, C])
           ↓
    Generate 1D coordinate grids for Y and X axes
           ↓
    Normalize coordinates to a fixed range (optional)
           ↓
    Apply sinusoidal functions of varying frequencies:
      - PE(pos, 2i)   = sin(pos / temp^(2i/d))
      - PE(pos, 2i+1) = cos(pos / temp^(2i/d))
           ↓
    Concatenate Y-axis and X-axis encodings
           ↓
    Transpose to channels-first format
           ↓
    Output(shape=[batch, 2 * num_pos_feats, H, W])
    ```

    **Mathematical Operation**:
    For each position `(y, x)` and feature dimension `i`, the encoding is:
        P_y(y, 2i)   = sin(y / T^(2i/d))
        P_y(y, 2i+1) = cos(y / T^(2i/d))
        P_x(x, 2i)   = sin(x / T^(2i/d))
        P_x(x, 2i+1) = cos(x / T^(2i/d))
    Where:
    - `d` is `num_pos_feats`
    - `T` is `temperature`

    Args:
        num_pos_feats: Integer, the number of features for the positional encoding.
            This corresponds to half the channel dimension of the final encoding.
            Defaults to 64.
        temperature: Float, the temperature value that controls the frequency of
            the sine and cosine functions. Defaults to 10000.0.
        normalize: Boolean, if True, normalizes the positional encodings by the
            spatial dimensions before applying trigonometric functions.
            Defaults to True.
        scale: Float, a scaling factor for the normalized positional encodings.
            Only used if `normalize` is True. Defaults to 2 * math.pi.
        **kwargs: Additional arguments for the Layer base class.

    Input shape:
        A 4D tensor with shape `(batch_size, height, width, channels)`. The channel
        dimension is not used but the spatial dimensions are required.

    Output shape:
        A 4D tensor with shape `(batch_size, 2 * num_pos_feats, height, width)`.

    Example:
        ```python
        # For a feature map from a CNN
        inputs = keras.Input(shape=(32, 32, 256))

        # Create positional encoding layer
        pos_encoding_layer = PositionEmbeddingSine2D(num_pos_feats=128)

        # Generate positional encodings
        # Output shape will be (batch, 256, 32, 32)
        pos_encodings = pos_encoding_layer(inputs)

        # The encodings would typically be added to the input features
        # after reshaping/transposing the input.
        ```
    """

    def __init__(
        self,
        num_pos_feats: int = 64,
        temperature: float = 10000.0,
        normalize: bool = True,
        scale: float = 2 * math.pi,
        **kwargs: Any
    ):
        super().__init__(**kwargs)

        # Validate inputs
        if num_pos_feats <= 0:
            raise ValueError(f"num_pos_feats must be positive, got {num_pos_feats}")
        if temperature <= 0:
            raise ValueError(f"temperature must be positive, got {temperature}")

        # Store configuration
        self.num_pos_feats = num_pos_feats
        self.temperature = temperature
        self.normalize = normalize
        self.scale = scale

    def call(self, inputs: keras.KerasTensor, mask: Optional[keras.KerasTensor] = None) -> keras.KerasTensor:
        """Forward pass to generate positional encodings."""
        if mask is None:
            # Assumes a 4D input (B, H, W, C), mask should be (B, H, W)
            mask = ops.zeros(ops.shape(inputs)[:3], dtype="bool")

        not_mask = ~mask
        y_embed = ops.cumsum(ops.cast(not_mask, "float32"), axis=1)
        x_embed = ops.cumsum(ops.cast(not_mask, "float32"), axis=2)

        if self.normalize:
            eps = 1e-6
            y_embed = (y_embed - 0.5) / (y_embed[:, -1:, :] + eps) * self.scale
            x_embed = (x_embed - 0.5) / (x_embed[:, :, -1:] + eps) * self.scale

        dim_t = ops.arange(self.num_pos_feats, dtype="float32")
        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)

        pos_x = x_embed[..., None] / dim_t
        pos_y = y_embed[..., None] / dim_t

        pos_x = ops.stack(
            [ops.sin(pos_x[..., 0::2]), ops.cos(pos_x[..., 1::2])], axis=4
        )
        pos_x = ops.reshape(pos_x, (*ops.shape(pos_x)[:3], -1))

        pos_y = ops.stack(
            [ops.sin(pos_y[..., 0::2]), ops.cos(pos_y[..., 1::2])], axis=4
        )
        pos_y = ops.reshape(pos_y, (*ops.shape(pos_y)[:3], -1))

        pos = ops.concatenate([pos_y, pos_x], axis=3)
        # Transpose to (batch, H, W, channels) -> (batch, channels, H, W)
        pos = ops.transpose(pos, [0, 3, 1, 2])
        return pos

    def compute_output_shape(self, input_shape: Tuple[Optional[int], ...]) -> Tuple[Optional[int], ...]:
        """Compute the output shape of the layer."""
        batch_size, h, w = input_shape[0], input_shape[1], input_shape[2]
        return batch_size, 2 * self.num_pos_feats, h, w

    def get_config(self) -> Dict[str, Any]:
        """Return configuration for serialization."""
        config = super().get_config()
        config.update({
            "num_pos_feats": self.num_pos_feats,
            "temperature": self.temperature,
            "normalize": self.normalize,
            "scale": self.scale
        })
        return config

# ---------------------------------------------------------------------
